{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0da8efc-0909-4b04-a2fa-b7822ea48ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys, platform\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "975c02b3-041f-4893-a2b9-164807dec6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bpandey1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "import os\n",
    "data = pd.read_csv(r'C:\\Users\\bpandey1\\Downloads\\ml\\winequality-red.csv',sep=';')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0258af5-b53a-4ca8-8fed-c5929ccfbbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58503df4-5705-4124-872d-eb175ab97faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352f6db-31a3-4055-9e71-59e9e944d347",
   "metadata": {},
   "source": [
    "RandomForest with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19952857-6d92-4879-bbf2-5a3d5e086b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.345973774586943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "rf_model = RandomForestRegressor(n_estimators=20,max_depth=10,min_samples_split=5,min_samples_leaf=5,max_features= None )\n",
    "rf_model.fit(x_train,y_train)\n",
    "y_pred = rf_model.predict(x_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse_rf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e67be980-4512-4614-a394-6ae6a8248d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features):\n",
    "    # Creating a Random Forest Regression Model and Fitting it to the Training Data\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators,max_depth=max_depth,min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf,max_features= max_features)\n",
    "    rf_model.fit(x_train,y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd0dc83c-cff7-42d3-8df7-c4d9f87b7198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bpandey1\\.conda\\envs\\pml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 48 is smaller than n_iter=100. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': (50, 400),\n",
    "    'max_depth': (1, 30),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'min_samples_leaf': (1, 4),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    " \n",
    " \n",
    "\n",
    "model_rf = RandomForestRegressor()\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=model_rf, \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=100, \n",
    "                                   cv=5, \n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# Perform the search\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66333b0b-88c0-48a4-b6c2-800e9fafb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators = best_params[ 'n_estimators']\n",
    "best_max_depth = best_params['max_depth']\n",
    "best_min_samples_split = best_params['min_samples_split']\n",
    "best_min_samples_leaf = best_params['min_samples_leaf']\n",
    "best_max_features = best_params['max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24160b03-a742-42e0-9c83-3600d73dcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized SearcCV for Random Fores algorithm:\n",
      "Mean Squared Error: 0.31560792968749996\n"
     ]
    }
   ],
   "source": [
    "y_pred = RF(best_n_estimators, best_max_depth, best_min_samples_split, best_min_samples_leaf, best_max_features)\n",
    "mse_rf = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Randomized SearcCV for Random Fores algorithm:\")\n",
    "print(\"Mean Squared Error:\", mse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c438633-4729-4def-bb0c-20b5e8ec75d2",
   "metadata": {},
   "source": [
    "Support Vector Machine using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0829b436-7c38-47c3-baf7-ea3cb115259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.4742553073530834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale')\n",
    "svr_model.fit(x_train, y_train)\n",
    "y_pred_svr = svr_model.predict(x_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "print(\"Mean Squared Error (MSE):\", mse_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9238f695-9153-4353-93b4-d7ea5fee59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def SVR_hpo(C, epsilon, gamma, kernel, degree):\n",
    "    # Creating a Random Forest Regression Model and Fitting it to the Training Data\n",
    "    #svm_model = SVR(C=C, gamma=gamma, kernel=kernel)\n",
    "   #svm_model.fit(x_train,y_train)\n",
    "   # y_pred = svm_model.predict(x_test)\n",
    "   # score = r2_score(y_test, y_pred)\n",
    "   # return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a47ba976-7cc3-4dc0-9d37-6fb485484017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for SVR: {'shrinking': True, 'kernel': 'rbf', 'gamma': 'auto', 'epsilon': 7906.043210907702, 'degree': 5, 'coef0': 1.0204081632653061, 'C': 37275937.20314938}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(3, 100),\n",
    "    'epsilon': np.logspace(3, 60),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': np.arange(1, 10),\n",
    "    'coef0': np.linspace(0, 15),\n",
    "    'shrinking': [True, False]\n",
    "}\n",
    "svr_model = SVR()\n",
    "random_search_svr = RandomizedSearchCV(estimator=svr_model,\n",
    "                                       param_distributions=param_grid,\n",
    "                                       n_iter=1,\n",
    "                                       cv=5,\n",
    "                                       random_state=42,\n",
    "                                       n_jobs=-1)\n",
    "# Perform the search\n",
    "random_search_svr.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_svr = random_search_svr.best_params_\n",
    "best_score_svr = random_search_svr.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters for SVR:\", best_params_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f00fcd10-536a-42ce-9d35-299df59e53d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using Best Parameters obtained from Hyperparameter optimization:\n",
      " The Mean Squared Error: 0.58125\n"
     ]
    }
   ],
   "source": [
    " # Using the best parameters to train the SVR model\n",
    "best_svr = SVR(**best_params_svr)\n",
    "best_svr.fit(x_train, y_train)\n",
    "y_pred_svr = best_svr.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(\" Using Best Parameters obtained from Hyperparameter optimization:\")\n",
    "print(\" The Mean Squared Error:\", mse_svr)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46cbfa-3e4f-4deb-99ef-417f2e6f707e",
   "metadata": {},
   "source": [
    "Bayesian Optimization for RandomForest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4a3b8fb-ef2f-47d3-a281-c2562003007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: OrderedDict([('max_depth', 27), ('max_features', 'log2'), ('min_samples_leaf', 1), ('min_samples_split', 9), ('n_estimators', 777)])\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'n_estimators': (50, 1000),\n",
    "           'max_depth': (1, 30),\n",
    "           'min_samples_split': (2, 10),\n",
    "           'max_features':  ('sqrt', 'log2', None),\n",
    "           'min_samples_leaf': (1, 4)}\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "optimizer = BayesSearchCV(\n",
    "    estimator=rf_model,\n",
    "    search_spaces=pbounds,\n",
    "    n_iter=1,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "optimizer.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = optimizer.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "984adc6f-bf33-458a-adf5-c02a8cab8a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPO using Bayesian Optimization  for Random Forest algorithm:\n",
      "Mean Squared Error: 0.32348603062388126\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_n_estimators = best_params['n_estimators']\n",
    "best_max_depth = best_params['max_depth']\n",
    "best_min_samples_split = best_params['min_samples_split']\n",
    "best_min_samples_leaf = best_params['min_samples_leaf']\n",
    "best_max_features = best_params['max_features']\n",
    "y_pred = RF(int(best_n_estimators), int(best_max_depth), int(best_min_samples_split), int(best_min_samples_leaf),best_max_features)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"HPO using Bayesian Optimization  for Random Forest algorithm:\")\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb84c96-22d4-479e-91f5-840bc24e219d",
   "metadata": {},
   "source": [
    " Bayesian Optimization For Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e512ff3d-0f85-4cff-a4af-c6ba0afcbd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: OrderedDict([('C', 301.85066224898054), ('coef0', 2.8749805200359195), ('degree', 1), ('epsilon', 376.72589518385706), ('gamma', 5.168141446685119), ('kernel', 'linear'), ('shrinking', True)])\n",
      "HPO using Bayesian Optimization for Support Vector Machine algorithm:\n",
      "Mean Squared Error: 0.58125\n",
      "Mean Absolute Error: 0.65\n",
      "R2 Score: -0.01535312180143289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "pbounds = {\n",
    "    'C': (1e-3, 1e3),\n",
    "    'epsilon': (1e-3, 1e3),\n",
    "    'gamma': (1e-6, 1e1),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': (1, 6),\n",
    "    'coef0': (0.0, 10.0),\n",
    "    'shrinking': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize SVR model\n",
    "svr_model = SVR()\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "optimizer = BayesSearchCV(\n",
    "    estimator=svr_model,\n",
    "    search_spaces=pbounds,\n",
    "    n_iter=1,\n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "optimizer.fit(x_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = optimizer.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_svr = SVR(**best_params)\n",
    "best_svr.fit(x_train, y_train)\n",
    "y_pred = best_svr.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"HPO using Bayesian Optimization for Support Vector Machine algorithm:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02512976-a5fb-46da-8250-cc6739d0f858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
